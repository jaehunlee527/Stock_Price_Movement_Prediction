{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and ML to predict stock price movement\n",
    "\n",
    "To anticipate the stock market is impossible, by all means today. Stock market (or perhaps any other market where irrationality supercedes rationalitity) is the most whimsical, unpredictable field. Even the most advanced machine learning or deep learning techniques have failed to bring consistent sum to gold miners.\n",
    "\n",
    "However, in a vain attempt to build a reliable, or at least a surviving mechanism that barely loses in the market, I have decided to derive several features, those of particular stock and those of commodities and indices that investors often refer to measure the sentiment of the market.\n",
    "\n",
    "I will be using ML tools to build a binary classifier, which tells the investors to either buy or sell 5 days prior to the next opening day. After that, we will see in the back testing to find out if the model has any usage. \n",
    "\n",
    "We will be testing with random forest classifier and neural network. \n",
    "\n",
    "## What features are we using?\n",
    "\n",
    "There are various, in fact hundreds of possible indicators. The following are examples of indicators we are going to use.\n",
    "\n",
    "- % Price change from previous trading day\n",
    "- Trade Volume\n",
    "- Moving Averages \n",
    "- MACD\n",
    "- Bollinger Bands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from finta import TA\n",
    "import ppscore as pps\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_caller(name):\n",
    "    \"\"\"\n",
    "    Fetches basic info about the stock\n",
    "    \n",
    "    :param 1 name: ticker symbol\n",
    "    :return: dataframe including volume, closing price, opening price, high price (during the day), low price\n",
    "    \"\"\"\n",
    "    df = yf.download(name)\n",
    "    if len(df) == 0:\n",
    "        raise NameError\n",
    "    \n",
    "    # Into lower case\n",
    "    df.rename(columns={'Volume':'volume','Close':'close','Open':'open','High':'high','Low':'low'}, inplace=True)\n",
    "    \n",
    "    # Fill any NaN values with prior \n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    Add column that shows whether closing price will go up or down the next trading day - serving as our target variable\n",
    "    \"\"\"\n",
    "    df['Target'] = 0\n",
    "    change_pct = (df.shift(-1)['close'] - df['close']) / df['close']\n",
    "    df['Target'][change_pct > 0] = 1\n",
    "    df['Target'][change_pct <= 0] = 0\n",
    "    \n",
    "    df = df.round(3)\n",
    "    \n",
    "    \n",
    "    def finta(df):\n",
    "        \"\"\"\n",
    "        Finta is a package that calls financial indicators for each ticker symbol.\n",
    "        For more info, refer to https://github.com/peerchemist/finta\n",
    "\n",
    "        Fetches +80 indicators from the given ticker symbol\n",
    "        \"\"\"\n",
    "\n",
    "        finta_df = pd.DataFrame()\n",
    "        indicators = dir(TA)[0:85]\n",
    "\n",
    "        # These indicators are either null or non-usable. Remove them from the list\n",
    "        n_a = ['ALMA','MAMA','FRAMA','LWMA','VIDYA','SWI','TMF','VR','QSTICK','STC','OBV']\n",
    "        indicators = [i for i in indicators if i not in n_a]\n",
    "\n",
    "        for ind in indicators:\n",
    "            series = eval(\"TA.\"+ind+\"(df)\")\n",
    "            ind_df = pd.DataFrame(series)\n",
    "\n",
    "            # When the indicator has more than one column\n",
    "            if len(ind_df.columns) > 1:\n",
    "                for col in ind_df:\n",
    "                    # Include only the indicator that has more than 90% of the rows filled\n",
    "                    if ind_df[col].count()/len(series) > 0.9:\n",
    "                        finta_df[ind+\"_\"+ind_df[col].name] = ind_df[col]\n",
    "            else: \n",
    "                if ind_df.count().values[0]/len(ind_df) > 0.9:\n",
    "                    finta_df[ind] = series\n",
    "\n",
    "        # Replace all infinity values with NaN\n",
    "        finta_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        return finta_df\n",
    " \n",
    "    df_finta = finta(df)\n",
    "    \n",
    "    # The date indices of df & df_finta must match\n",
    "    mask = df_finta.index.isin(df.index)\n",
    "    df = pd.concat([df, df_finta[mask]], axis=1)\n",
    "    \n",
    "    # Since the percentage of missing entries are low, fill NaN values with previous values\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    return df \n",
    "       \n",
    "def standardize(df):\n",
    "    scaler = StandardScaler()\n",
    "    for col in df:\n",
    "        df[col] = scaler.fit_transform(np.array(df[col]).reshape(-1,1))\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def reduce_dimension(df, num_att, mode=[\"pps\",\"pca\"], show_pps=False):\n",
    "        \n",
    "    if mode == \"pps\":\n",
    "        \"\"\"\n",
    "        Returns top num_att number of indicators, based on their predictive power to target value.\n",
    "        \"\"\"\n",
    "            \n",
    "        # Get top indicators based on their predictive powers with respect to the target variable\n",
    "        top = pps.predictors(df, \"Target\", sorted=True)[1:num_att+1]['x']\n",
    "        df_top = df[top]\n",
    "\n",
    "        # Drop any rows with nan \n",
    "        df_top.dropna(axis='index', inplace=True)\n",
    "        \n",
    "        # If the user wants to see the ppscore in the descending order\n",
    "        if show_pps == True:\n",
    "            print(pps.predictors(df, \"Target\", sorted=True)[1:num_att+1])\n",
    "        \n",
    "        df_top = df_top.join(df['Target'], on=\"Date\")\n",
    "        \n",
    "        return df_top\n",
    "        \n",
    "    elif mode == \"pca\":\n",
    "        target = df['Target']\n",
    "        df.drop(['Target'], axis=1, inplace=True)\n",
    "            \n",
    "        pca = PCA(n_components=num_att)\n",
    "        df_top = pd.DataFrame(pca.fit_transform(df))\n",
    "        df_top.index = df.index\n",
    "        df_top = df_top.join(target, on=\"Date\")\n",
    "        \n",
    "        return df_top\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Not a valid mode\")\n",
    "   \n",
    "\n",
    "def split(X, y, train_size=None, start_date=None, split_mode=[\"Size\",\"Date\"]):\n",
    "    \"\"\"\n",
    "    Split based on either time frame, or size\n",
    "    \"\"\"\n",
    "    #x = df.drop(['Target'], axis=1)\n",
    "    #y = df['Target']\n",
    "    \n",
    "    if split_mode == \"Size\":\n",
    "        # Split test and train by size\n",
    "        train_len = int(len(X)*train_size)\n",
    "        X_train = X.iloc[0:train_len]\n",
    "        X_test = X.iloc[train_len:]\n",
    "        y_train = y.iloc[0:train_len]\n",
    "        y_test = y.iloc[train_len:]\n",
    "            \n",
    "    elif split_mode == \"Date\":\n",
    "        # Split test and train by starting date\n",
    "        X_train = X.loc[:start_date]\n",
    "        X_test = X.loc[start_date:]\n",
    "        y_train = y.loc[:start_date]\n",
    "        y_test = y.loc[start_date:]\n",
    "    else:\n",
    "        raise ValueError(\"Not a valid split mode\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def add_change(df, n):\n",
    "    \"\"\"\n",
    "    Add changes with respect to previous days' indicators\n",
    "    \"\"\"    \n",
    "    target = df[\"Target\"]\n",
    "    df = df.drop(\"Target\",1)\n",
    "\n",
    "    drop_columns = df.loc[:, (df == 0.0).any(axis=0)].columns\n",
    "\n",
    "    df = df.drop(drop_columns,1)\n",
    "    df_tmp = df.copy()\n",
    "    \n",
    "    for i in range(1,n+1):\n",
    "        delta = df_tmp - df_tmp.shift(i)\n",
    "        df_final = delta / df_tmp.shift(i)\n",
    "        df_final.columns = [c + \"_\" + str(i) for c in df_final.columns]\n",
    "        df = df.join(df_final)\n",
    "        \n",
    "    df[\"Target\"] = target\n",
    "    df = df[n:]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neural Network \n",
    "\"\"\"\n",
    "\n",
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, hidden_dim_2):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and \n",
    "        assign them as member variables.\n",
    "        \"\"\"\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.lin_1 = torch.nn.Linear(input_size, hidden_dim)\n",
    "        self.lin_2 = torch.nn.Linear(hidden_dim, hidden_dim_2)\n",
    "        self.lin_3 = torch.nn.Linear(hidden_dim_2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Compute the forward pass of our model, which outputs logits.\n",
    "        \"\"\"\n",
    "        x = self.lin_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin_3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictor Class \n",
    "\"\"\"\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.pred = None\n",
    "    \n",
    "    def train(self, X_train, y_train, model_type=[\"random_forest\"]): \n",
    "    \n",
    "        if model_type == \"random_forest\":\n",
    "            \"\"\"\n",
    "            Random Forest Classifier\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            # Grid Search - Hyperparameter tuning first\n",
    "            param_grid = { \n",
    "                'n_estimators': [150,200,300,400],\n",
    "                'max_features': ['auto'],\n",
    "                'max_depth' : [2,3,4],\n",
    "                'criterion' :['gini']\n",
    "            }\n",
    "\n",
    "            forest_clf = RandomForestClassifier(random_state=42)\n",
    "            CV = GridSearchCV(estimator=forest_clf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "            CV.fit(X_train, y_train)\n",
    "            self.model = CV.best_estimator_\n",
    "            \"\"\"\n",
    "            self.model = RandomForestClassifier(max_depth=2, n_estimators=400, random_state=42)\n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"Cross Validation Score: \", cross_val_score(self.model, X_train, y_train, cv=5))\n",
    "            \n",
    "            print(\"Training Complete\")\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Wrong Model Input\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        pred = self.model.predict(X_test)\n",
    "        df_pred = pd.DataFrame(pred)\n",
    "        df_pred.index = X_test.index\n",
    "        df_pred.columns = ['Target']\n",
    "        \n",
    "        self.pred = df_pred\n",
    "        \n",
    "        return df_pred\n",
    "    \n",
    "    def confusion_matrix(self, pred, y_test):\n",
    "        matrix = confusion_matrix(y_test, pred, labels=[1,0,-1])\n",
    "\n",
    "        \"\"\"\n",
    "        # Show precision/recall and F1 Score for each class\n",
    "        precision_up = matrix[0,0] / np.sum(matrix[:,0])\n",
    "        recall_up = matrix[0,0] / np.sum(matrix[0,:])\n",
    "        precision_down = matrix[2,2] / np.sum(matrix[:,2])\n",
    "        recall_down = matrix[2,2] / np.sum(matrix[2,:])\n",
    "        f1_up = 2*(precision_up * recall_up)/(precision_up + recall_up)\n",
    "        f1_down = 2*(precision_down * recall_down)/(precision_down + recall_down)\n",
    "\n",
    "        print(\"Up Precision: \", precision_up, \"Up Recall: \", recall_up, \"Up F1 Score: \", f1_up)\n",
    "        print(\"Down Precision: \", precision_down, \"Down Recall: \", recall_down, \"Down F1 Score: \", f1_down)\n",
    "        \"\"\"\n",
    "        print(\"<Confusion Matrix>\")\n",
    "        display(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BackTester Class - We want to see if the trained model will make us money\n",
    "\"\"\"\n",
    "\n",
    "class BackTester:\n",
    "    \n",
    "    def __init__(self, df, df_pred, seed):\n",
    "        self.df_merge = pd.merge(df, df_pred, how='left', on='Date')\n",
    "        \n",
    "        # Dates with long signal\n",
    "        self.long_date = df_pred[df_pred['Target'] == 1].index.sort_values(ascending=True)\n",
    "        # Dates with short signal\n",
    "        self.short_date = df_pred[df_pred['Target'] == -1].index.sort_values(ascending=True)\n",
    "        # Seed money for each transaction \n",
    "        self.seed = 1000 \n",
    "        self.balance = 0\n",
    "    \n",
    "    \n",
    "    def show(self):\n",
    "        return self.df_merge\n",
    "    \n",
    "    def long_transaction(self):\n",
    "        df_shift = self.df_merge.shift(-1)['close'] - self.df_merge['close']\n",
    "        df_share_amt = self.seed / self.df_merge.loc[self.long_date]['close']\n",
    "        profit = np.sum(df_shift[self.long_date] * df_share_amt)\n",
    "        self.balance += 100 \n",
    "        print(\"Profit from Long Positions: \", profit)\n",
    "        print(\"Total invested amount: \", len(self.long_date) * self.seed)\n",
    "\n",
    "        return profit\n",
    "\n",
    "    def short_transaction(self):\n",
    "        df_shift = self.df_merge['close'] - self.df_merge.shift(-1)['close']\n",
    "        df_share_amt = self.seed / self.df_merge.loc[self.short_date]['close']\n",
    "        profit = np.sum(df_shift[self.short_date] * df_share_amt)\n",
    "        print(\"Profit from Short Positions: \", profit)\n",
    "        return profit\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#comp_list = [\"WMT\",\"SPY\",\"F\",\"AAL\",\"AMZN\"]\n",
    "comp_list = [\"BTC-USD\"]\n",
    "# First make list of data frames, so we only have to call once\n",
    "df_list = []\n",
    "\n",
    "for c in comp_list:\n",
    "    df_list.append(df_caller(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Target</th>\n",
       "      <th>up_move</th>\n",
       "      <th>down_move</th>\n",
       "      <th>plus</th>\n",
       "      <th>...</th>\n",
       "      <th>VPT</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>VW_MACD_MACD</th>\n",
       "      <th>VW_MACD_SIGNAL</th>\n",
       "      <th>VZO</th>\n",
       "      <th>WILLIAMS</th>\n",
       "      <th>WMA</th>\n",
       "      <th>WOBV</th>\n",
       "      <th>WTO_WT1.</th>\n",
       "      <th>WTO_WT2.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-09-17</th>\n",
       "      <td>465.864</td>\n",
       "      <td>468.174</td>\n",
       "      <td>452.422</td>\n",
       "      <td>457.334</td>\n",
       "      <td>457.334</td>\n",
       "      <td>21056800</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.314</td>\n",
       "      <td>39.318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.280530e+07</td>\n",
       "      <td>459.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-84.672796</td>\n",
       "      <td>414.968400</td>\n",
       "      <td>-1.134290e+09</td>\n",
       "      <td>-121.212121</td>\n",
       "      <td>-107.305199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-18</th>\n",
       "      <td>456.860</td>\n",
       "      <td>456.860</td>\n",
       "      <td>413.104</td>\n",
       "      <td>424.440</td>\n",
       "      <td>424.440</td>\n",
       "      <td>34483200</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.314</td>\n",
       "      <td>39.318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.390436e+07</td>\n",
       "      <td>442.023697</td>\n",
       "      <td>-0.674881</td>\n",
       "      <td>-0.374934</td>\n",
       "      <td>-65.392780</td>\n",
       "      <td>-84.672796</td>\n",
       "      <td>414.968400</td>\n",
       "      <td>-1.134290e+09</td>\n",
       "      <td>-121.212121</td>\n",
       "      <td>-107.305199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-19</th>\n",
       "      <td>424.103</td>\n",
       "      <td>427.835</td>\n",
       "      <td>384.532</td>\n",
       "      <td>394.796</td>\n",
       "      <td>394.796</td>\n",
       "      <td>37919700</td>\n",
       "      <td>1</td>\n",
       "      <td>-29.025</td>\n",
       "      <td>28.572</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.252316e+08</td>\n",
       "      <td>425.942045</td>\n",
       "      <td>-1.611998</td>\n",
       "      <td>-0.881927</td>\n",
       "      <td>-81.086126</td>\n",
       "      <td>-84.672796</td>\n",
       "      <td>414.968400</td>\n",
       "      <td>-2.258382e+09</td>\n",
       "      <td>-119.243038</td>\n",
       "      <td>-107.305199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-20</th>\n",
       "      <td>394.673</td>\n",
       "      <td>423.296</td>\n",
       "      <td>389.883</td>\n",
       "      <td>408.904</td>\n",
       "      <td>408.904</td>\n",
       "      <td>36863600</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.539</td>\n",
       "      <td>-5.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.383034e+07</td>\n",
       "      <td>420.686161</td>\n",
       "      <td>-1.383672</td>\n",
       "      <td>-1.051895</td>\n",
       "      <td>-20.030918</td>\n",
       "      <td>-84.672796</td>\n",
       "      <td>414.968400</td>\n",
       "      <td>-1.738310e+09</td>\n",
       "      <td>-99.111982</td>\n",
       "      <td>-107.305199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-21</th>\n",
       "      <td>408.085</td>\n",
       "      <td>412.426</td>\n",
       "      <td>393.181</td>\n",
       "      <td>398.821</td>\n",
       "      <td>398.821</td>\n",
       "      <td>26580100</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.870</td>\n",
       "      <td>-3.298</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.194202e+08</td>\n",
       "      <td>417.431878</td>\n",
       "      <td>-1.610392</td>\n",
       "      <td>-1.218035</td>\n",
       "      <td>-37.548910</td>\n",
       "      <td>-84.672796</td>\n",
       "      <td>414.968400</td>\n",
       "      <td>-2.006317e+09</td>\n",
       "      <td>-89.653657</td>\n",
       "      <td>-107.305199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-13</th>\n",
       "      <td>50114.742</td>\n",
       "      <td>50205.000</td>\n",
       "      <td>45894.848</td>\n",
       "      <td>46737.480</td>\n",
       "      <td>46737.480</td>\n",
       "      <td>32166727776</td>\n",
       "      <td>0</td>\n",
       "      <td>-519.867</td>\n",
       "      <td>2831.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.089329e+12</td>\n",
       "      <td>26644.066324</td>\n",
       "      <td>-2984.745073</td>\n",
       "      <td>-2609.352038</td>\n",
       "      <td>-12.538408</td>\n",
       "      <td>-76.212118</td>\n",
       "      <td>48743.012067</td>\n",
       "      <td>4.599596e+14</td>\n",
       "      <td>-57.030737</td>\n",
       "      <td>-58.351018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-14</th>\n",
       "      <td>46709.824</td>\n",
       "      <td>48431.398</td>\n",
       "      <td>46424.496</td>\n",
       "      <td>46612.633</td>\n",
       "      <td>46612.633</td>\n",
       "      <td>34638619079</td>\n",
       "      <td>1</td>\n",
       "      <td>-1773.602</td>\n",
       "      <td>-529.648</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.085974e+12</td>\n",
       "      <td>26662.990709</td>\n",
       "      <td>-3100.444691</td>\n",
       "      <td>-2707.570569</td>\n",
       "      <td>-24.965471</td>\n",
       "      <td>-76.878824</td>\n",
       "      <td>48237.314089</td>\n",
       "      <td>4.556351e+14</td>\n",
       "      <td>-57.889124</td>\n",
       "      <td>-57.654383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-15</th>\n",
       "      <td>48379.754</td>\n",
       "      <td>49473.957</td>\n",
       "      <td>46671.965</td>\n",
       "      <td>48896.723</td>\n",
       "      <td>48896.723</td>\n",
       "      <td>36541828520</td>\n",
       "      <td>0</td>\n",
       "      <td>1042.559</td>\n",
       "      <td>-247.469</td>\n",
       "      <td>1042.559</td>\n",
       "      <td>...</td>\n",
       "      <td>4.099458e+12</td>\n",
       "      <td>26684.075497</td>\n",
       "      <td>-2935.777347</td>\n",
       "      <td>-2753.211925</td>\n",
       "      <td>-6.539174</td>\n",
       "      <td>-58.774020</td>\n",
       "      <td>48249.683333</td>\n",
       "      <td>5.390999e+14</td>\n",
       "      <td>-55.281234</td>\n",
       "      <td>-56.536352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-16</th>\n",
       "      <td>48900.465</td>\n",
       "      <td>49425.574</td>\n",
       "      <td>47529.879</td>\n",
       "      <td>47665.426</td>\n",
       "      <td>47665.426</td>\n",
       "      <td>27268150947</td>\n",
       "      <td>0</td>\n",
       "      <td>-48.383</td>\n",
       "      <td>-857.914</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.063928e+12</td>\n",
       "      <td>26699.680705</td>\n",
       "      <td>-2898.727524</td>\n",
       "      <td>-2782.315044</td>\n",
       "      <td>-17.068076</td>\n",
       "      <td>-67.203202</td>\n",
       "      <td>48053.257667</td>\n",
       "      <td>5.055247e+14</td>\n",
       "      <td>-53.070140</td>\n",
       "      <td>-55.817809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-17</th>\n",
       "      <td>47561.852</td>\n",
       "      <td>47999.234</td>\n",
       "      <td>45682.039</td>\n",
       "      <td>46285.660</td>\n",
       "      <td>46285.660</td>\n",
       "      <td>32606277632</td>\n",
       "      <td>0</td>\n",
       "      <td>-1426.340</td>\n",
       "      <td>1847.840</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.028012e+12</td>\n",
       "      <td>26716.967360</td>\n",
       "      <td>-2949.733158</td>\n",
       "      <td>-2815.798667</td>\n",
       "      <td>-28.224459</td>\n",
       "      <td>-69.075036</td>\n",
       "      <td>47648.315689</td>\n",
       "      <td>4.605357e+14</td>\n",
       "      <td>-54.691676</td>\n",
       "      <td>-55.233043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2645 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 open       high        low      close  Adj Close  \\\n",
       "Date                                                                \n",
       "2014-09-17    465.864    468.174    452.422    457.334    457.334   \n",
       "2014-09-18    456.860    456.860    413.104    424.440    424.440   \n",
       "2014-09-19    424.103    427.835    384.532    394.796    394.796   \n",
       "2014-09-20    394.673    423.296    389.883    408.904    408.904   \n",
       "2014-09-21    408.085    412.426    393.181    398.821    398.821   \n",
       "...               ...        ...        ...        ...        ...   \n",
       "2021-12-13  50114.742  50205.000  45894.848  46737.480  46737.480   \n",
       "2021-12-14  46709.824  48431.398  46424.496  46612.633  46612.633   \n",
       "2021-12-15  48379.754  49473.957  46671.965  48896.723  48896.723   \n",
       "2021-12-16  48900.465  49425.574  47529.879  47665.426  47665.426   \n",
       "2021-12-17  47561.852  47999.234  45682.039  46285.660  46285.660   \n",
       "\n",
       "                 volume  Target   up_move  down_move      plus  ...  \\\n",
       "Date                                                            ...   \n",
       "2014-09-17     21056800       0   -11.314     39.318     0.000  ...   \n",
       "2014-09-18     34483200       0   -11.314     39.318     0.000  ...   \n",
       "2014-09-19     37919700       1   -29.025     28.572     0.000  ...   \n",
       "2014-09-20     36863600       0    -4.539     -5.351     0.000  ...   \n",
       "2014-09-21     26580100       1   -10.870     -3.298     0.000  ...   \n",
       "...                 ...     ...       ...        ...       ...  ...   \n",
       "2021-12-13  32166727776       0  -519.867   2831.004     0.000  ...   \n",
       "2021-12-14  34638619079       1 -1773.602   -529.648     0.000  ...   \n",
       "2021-12-15  36541828520       0  1042.559   -247.469  1042.559  ...   \n",
       "2021-12-16  27268150947       0   -48.383   -857.914     0.000  ...   \n",
       "2021-12-17  32606277632       0 -1426.340   1847.840     0.000  ...   \n",
       "\n",
       "                     VPT          VWAP  VW_MACD_MACD  VW_MACD_SIGNAL  \\\n",
       "Date                                                                   \n",
       "2014-09-17 -2.280530e+07    459.310000      0.000000        0.000000   \n",
       "2014-09-18 -7.390436e+07    442.023697     -0.674881       -0.374934   \n",
       "2014-09-19 -1.252316e+08    425.942045     -1.611998       -0.881927   \n",
       "2014-09-20 -9.383034e+07    420.686161     -1.383672       -1.051895   \n",
       "2014-09-21 -1.194202e+08    417.431878     -1.610392       -1.218035   \n",
       "...                  ...           ...           ...             ...   \n",
       "2021-12-13  4.089329e+12  26644.066324  -2984.745073    -2609.352038   \n",
       "2021-12-14  4.085974e+12  26662.990709  -3100.444691    -2707.570569   \n",
       "2021-12-15  4.099458e+12  26684.075497  -2935.777347    -2753.211925   \n",
       "2021-12-16  4.063928e+12  26699.680705  -2898.727524    -2782.315044   \n",
       "2021-12-17  4.028012e+12  26716.967360  -2949.733158    -2815.798667   \n",
       "\n",
       "                  VZO   WILLIAMS           WMA          WOBV    WTO_WT1.  \\\n",
       "Date                                                                       \n",
       "2014-09-17   0.000000 -84.672796    414.968400 -1.134290e+09 -121.212121   \n",
       "2014-09-18 -65.392780 -84.672796    414.968400 -1.134290e+09 -121.212121   \n",
       "2014-09-19 -81.086126 -84.672796    414.968400 -2.258382e+09 -119.243038   \n",
       "2014-09-20 -20.030918 -84.672796    414.968400 -1.738310e+09  -99.111982   \n",
       "2014-09-21 -37.548910 -84.672796    414.968400 -2.006317e+09  -89.653657   \n",
       "...               ...        ...           ...           ...         ...   \n",
       "2021-12-13 -12.538408 -76.212118  48743.012067  4.599596e+14  -57.030737   \n",
       "2021-12-14 -24.965471 -76.878824  48237.314089  4.556351e+14  -57.889124   \n",
       "2021-12-15  -6.539174 -58.774020  48249.683333  5.390999e+14  -55.281234   \n",
       "2021-12-16 -17.068076 -67.203202  48053.257667  5.055247e+14  -53.070140   \n",
       "2021-12-17 -28.224459 -69.075036  47648.315689  4.605357e+14  -54.691676   \n",
       "\n",
       "              WTO_WT2.  \n",
       "Date                    \n",
       "2014-09-17 -107.305199  \n",
       "2014-09-18 -107.305199  \n",
       "2014-09-19 -107.305199  \n",
       "2014-09-20 -107.305199  \n",
       "2014-09-21 -107.305199  \n",
       "...                ...  \n",
       "2021-12-13  -58.351018  \n",
       "2021-12-14  -57.654383  \n",
       "2021-12-15  -56.536352  \n",
       "2021-12-16  -55.817809  \n",
       "2021-12-17  -55.233043  \n",
       "\n",
       "[2645 rows x 126 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Step:  2000\n",
      "Training Accuracy:  0.45569620253164556\n",
      "Loss:  1209901.375\n",
      "Current Step:  4000\n",
      "Training Accuracy:  0.5316455696202531\n",
      "Loss:  207104.609375\n",
      "Current Step:  6000\n",
      "Training Accuracy:  0.5654008438818565\n",
      "Loss:  67807.2421875\n",
      "Current Step:  8000\n",
      "Training Accuracy:  0.5738396624472574\n",
      "Loss:  29672.57421875\n",
      "Current Step:  10000\n",
      "Training Accuracy:  0.5527426160337553\n",
      "Loss:  5355.74755859375\n",
      "Current Step:  12000\n",
      "Training Accuracy:  0.5611814345991561\n",
      "Loss:  5277.498046875\n",
      "Current Step:  14000\n",
      "Training Accuracy:  0.6413502109704642\n",
      "Loss:  2788.289794921875\n",
      "Current Step:  16000\n",
      "Training Accuracy:  0.5443037974683544\n",
      "Loss:  2831.52294921875\n",
      "Current Step:  18000\n",
      "Training Accuracy:  0.5232067510548524\n",
      "Loss:  0.6907839179039001\n",
      "Current Step:  20000\n",
      "Training Accuracy:  0.5274261603375527\n",
      "Loss:  0.6922550797462463\n",
      "Current Step:  22000\n",
      "Training Accuracy:  0.5358649789029536\n",
      "Loss:  0.6882731914520264\n",
      "Current Step:  24000\n",
      "Training Accuracy:  0.4978902953586498\n",
      "Loss:  0.6976093649864197\n",
      "Current Step:  26000\n",
      "Training Accuracy:  0.5611814345991561\n",
      "Loss:  0.6833404898643494\n",
      "Current Step:  28000\n",
      "Training Accuracy:  0.5485232067510548\n",
      "Loss:  0.6886112093925476\n",
      "Current Step:  30000\n",
      "Training Accuracy:  0.5485232067510548\n",
      "Loss:  0.6859468221664429\n"
     ]
    }
   ],
   "source": [
    "# For neural network\n",
    "\n",
    "for df in df_list:\n",
    "    df_final = add_change(df,4)\n",
    "    #df_final = reduce_dimension(df_final, 50, 'pca')\n",
    "    \n",
    "    y = df_final['Target']\n",
    "    X = df_final.drop(['Target'], axis=1)\n",
    "    \n",
    "    columns = X.columns\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X, columns=columns, index=X.index)\n",
    "    \n",
    "    # Split the train and test set\n",
    "    X_train, X_test, y_train, y_test = split(X_scaled, y, train_size = 0.9, split_mode=\"Size\")\n",
    "    \n",
    "    model = FeedForward(X_train.shape[1], 100,30)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "    for step in range(1, 30001):\n",
    "        i = np.random.choice(X_train.shape[0], size=int(X_train.shape[0]/10), replace=False)\n",
    "        x = torch.from_numpy(np.array(X_train.iloc[i]).astype(np.float32))\n",
    "        y = torch.from_numpy(np.array(y_train.iloc[i]).astype(np.int))\n",
    "        y = y.type(torch.LongTensor)\n",
    "        \n",
    "        # Forward pass: Get logits for x\n",
    "        logits = model(x)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            print(\"Current Step: \", step)\n",
    "            idxs = np.random.choice(len(X_train), int(X_train.shape[0]/10), replace=False)\n",
    "            x = torch.from_numpy(np.array(X_train.iloc[idxs]).astype(np.float32))\n",
    "            y = torch.from_numpy(np.array(y_train.iloc[idxs]).astype(np.int))\n",
    "            y = y.type(torch.LongTensor)\n",
    "            \n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            y_pred = torch.max(logits, 1)[1]\n",
    "            print(\"Training Accuracy: \", accuracy_score(y_train.iloc[idxs], y_pred.numpy()))\n",
    "            print(\"Loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.9778,  1.0072,  1.0967,  ..., -1.9315, -1.8892, -2.9066],\n",
      "        [-0.5674, -0.6120, -0.6623,  ..., -4.7677, -1.5417,  3.0041],\n",
      "        [ 0.0113, -0.0415, -0.0386,  ...,  0.0362, -0.0066,  0.0386],\n",
      "        ...,\n",
      "        [-0.0320, -0.0325,  0.0133,  ..., -0.0380, -0.0391,  0.0248],\n",
      "        [-0.4847, -0.4746, -0.4839,  ..., -0.5350, -1.1098,  1.8839],\n",
      "        [-0.3863, -0.3519, -0.2928,  ..., -1.9841, -1.9160, -2.9267]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-5.8195e+00, -3.5720e+00, -3.3043e-02, -4.2634e+00,  1.9632e-02,\n",
      "        -9.8726e-02, -3.2843e-02,  2.8026e-02, -8.6571e-03,  2.3046e-02,\n",
      "         8.2812e-05, -4.1152e-02,  1.4630e+00, -8.2467e+00,  1.9157e-02,\n",
      "         3.1640e-03,  4.2267e-02,  3.9871e+00, -4.5641e-02,  3.5866e-02,\n",
      "        -3.3285e-02,  8.7165e+00, -3.4968e-02, -9.2006e+00, -9.1567e-01,\n",
      "        -1.2748e+00,  1.1885e-02,  8.8165e+00, -4.2710e-02, -4.8104e+00,\n",
      "        -1.3292e-02,  1.5529e-02,  1.3616e+00, -7.1117e-02, -2.4501e-03,\n",
      "        -3.5366e-02,  7.6578e-02, -3.7099e-02,  2.9597e+00, -3.5442e-02,\n",
      "        -4.3011e-02, -2.7204e-02, -4.2901e-02, -8.8536e+00, -1.4796e-02,\n",
      "        -3.6884e+00, -3.6330e-01,  2.9569e+00, -1.5606e-02,  4.8210e+00,\n",
      "        -5.8696e+00,  4.2786e+00, -1.0753e+01,  1.7348e-02,  2.2933e-02,\n",
      "        -6.1607e-02,  9.3067e-03, -5.8307e-03,  6.2486e+00,  5.4056e+00,\n",
      "         2.9807e-02,  1.7095e-02, -2.5773e-02,  3.8479e+00, -1.3315e-01,\n",
      "        -2.4766e-02,  2.7669e-02, -5.8392e-03, -9.9348e+00, -5.0064e+00,\n",
      "         4.1731e+00,  8.1665e-02,  5.6609e-03,  1.0072e-03,  3.9479e+00,\n",
      "        -6.7717e+00, -3.3472e+00,  3.6700e+00, -3.8986e-04,  1.2951e+00,\n",
      "        -2.5558e+00, -3.6149e-02, -3.5923e-02,  3.0748e+00,  1.3880e-02,\n",
      "        -1.9181e-02,  2.8507e+00,  4.3357e-02, -3.1954e+00, -5.2240e-02,\n",
      "        -2.4832e-02, -5.3882e-02, -2.8110e+00,  3.1966e-02, -2.1738e-02,\n",
      "        -8.8764e-04, -1.1851e-03, -1.4346e-02, -3.9097e+00, -6.3129e+00],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0377, -0.0284,  0.0639,  ..., -0.0240, -0.0469,  0.0753],\n",
      "        [ 0.0467,  0.0320,  0.0140,  ...,  0.0272, -0.0665, -0.0633],\n",
      "        [ 0.0385, -0.0019,  0.0708,  ...,  0.0395, -0.0798, -0.0517],\n",
      "        ...,\n",
      "        [ 0.0684, -0.0496, -0.0084,  ...,  0.0267,  0.0992, -0.0201],\n",
      "        [ 0.0251, -0.0691, -0.0130,  ..., -0.0580,  0.0058, -0.0822],\n",
      "        [-0.0710, -0.0445,  0.0448,  ...,  0.0019, -0.0036,  0.0460]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1111,  0.0711, -0.1160, -0.0501, -2.5991, -4.8725,  0.0486, -5.5180,\n",
      "        -0.0542, -0.0798, -0.1052, -0.1754, -0.1946, -0.0784, -0.8598,  0.1961,\n",
      "        -0.0514,  0.0377, -1.6731,  0.1041,  6.2869,  0.9999, -0.4533, -3.0535,\n",
      "        -0.1043, -2.6637, -0.1561, -0.1058, -0.2301, -3.6535],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0539,  0.0620,  0.0142,  0.1628,  0.1378,  0.1205,  0.0006, -0.1346,\n",
      "          0.0219,  0.0325, -0.1082,  0.0277,  0.0146,  0.0675,  0.1322,  0.0824,\n",
      "         -0.0843, -0.0108,  0.1190,  0.0115, -0.0568,  0.1442,  0.0065, -0.1609,\n",
      "          0.0767,  0.0267, -0.0362, -0.0320,  0.0743,  0.2226],\n",
      "        [-0.0286, -0.0939,  0.0264, -0.0969,  0.1468,  0.1321,  0.1824,  0.0127,\n",
      "         -0.1138, -0.1305, -0.0655, -0.1258, -0.0672,  0.1530,  0.1684, -0.0139,\n",
      "         -0.1698, -0.1357,  0.1928,  0.0219, -0.0123,  0.0259, -0.0528, -0.0803,\n",
      "         -0.0485, -0.0054, -0.0385,  0.0233,  0.1057,  0.0992]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1245,  0.0410], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5056603773584906\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "x = torch.from_numpy(np.array(X_test).astype(np.float32))\n",
    "logits = model(x)\n",
    "pred = torch.max(logits, 1)[1]\n",
    "print(\"Test accuracy: \", accuracy_score(pred, y_test))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.45168067 0.54736842 0.54736842 0.54315789 0.45894737]\n",
      "Training Complete\n",
      "Accuracy:  0.5056603773584906\n",
      "<Confusion Matrix>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[125,   0,   9],\n",
       "       [  1,   0,   0],\n",
       "       [121,   0,   9]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and Testing with Random Forest \n",
    "\n",
    "for df in df_list:\n",
    "    df_final = add_change(df,3)\n",
    "    df_final = reduce_dimension(df_final, 30, 'pca')\n",
    "    \n",
    "    y = df_final['Target']\n",
    "    X = df_final.drop(['Target'], axis=1)\n",
    "    \n",
    "    # Split the train and test set\n",
    "    X_train, X_test, y_train, y_test = split(X, y, train_size = 0.9, split_mode=\"Size\")\n",
    "\n",
    "    predictor = Predictor()\n",
    "    predictor.train(X_train, y_train, model_type = \"random_forest\")\n",
    "    pred = predictor.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy: \", accuracy_score(pred, y_test))\n",
    "    display(predictor.confusion_matrix(pred, y_test))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
